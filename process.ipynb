{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Prototype: Agentic RAG System with Nursing Handbooks and Transes as Knowledge Base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this project is to create an **Agentic RAG-based system** that helps nursing students retrieve relevant information from nursing handbooks and their personal study notes. This system will augment the responses with context from the personal notes, making it more personalized and adaptive to the user's learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flow Overview\n",
    "\n",
    "The project involves two primary stages:\n",
    "1. **Prepopulating the Vector DB** (embedding the nursing handbooks and personal notes into a database)\n",
    "2. **RAG Modeling** (retrieving relevant information and augmenting responses using both the handbooks and personal notes)\n",
    "\n",
    "Additionally, there will be an **Agentic Layer** that intelligently routes queries to the appropriate source (nursing handbooks or personal study notes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Technologies to use\n",
    "\n",
    "- **Docling**: For converting nursing handbooks and personal notes into AI-friendly markdown format.\n",
    "- **OpenAI Embedding Model (large)**: For embedding both nursing handbooks and personal study notes.\n",
    "- **ChromaDB**: For storing and querying the embeddings.\n",
    "- **Deepseek LLM**: For augmenting responses based on the retrieved content.\n",
    "- **Pydantic AI**: For AI agent intelligently routing queries between the nursing handbooks and personal notes. \n",
    "- **Pydantic**: For type safety and data validation.\n",
    "- **FastAPI**: For building the API.\n",
    "- **Docker**: For containerization and deployment.\n",
    "- **Pydantic Graphs**: For workflow pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from docling.document_converter import DocumentConverter\n",
    "\n",
    "knowledge_base_raw_path = './data/knowledge-base/raw/'\n",
    "knowledge_base_converted_path = './data/knowledge-base/converted/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 1: Prepopulate the Vector DB\n",
    "\n",
    "In this stage, we process nursing handbooks and personal study notes, embedding them into a vector database for efficient retrieval during RAG modeling.\n",
    "\n",
    "#### Steps:\n",
    "\n",
    "1. **Upload Nursing Handbooks**:\n",
    "   - Upload nursing handbooks in popular formats like PDF or DOCX.\n",
    "   - These documents may include textbooks on topics like **medical-surgical nursing, pharmacology, pediatric nursing**, and other specialized nursing areas.\n",
    "\n",
    "2. **Convert Documents into AI-Friendly Markdown Format**:\n",
    "   - Use **Docling** to convert nursing handbooks and personal notes into markdown format.\n",
    "   - The conversion ensures that headings, bullet points, tables, and other relevant formatting are preserved, making it easier for the AI to process.\n",
    "\n",
    "3. **Generate Embeddings**:\n",
    "   - Use **OpenAI's large embedding model** to convert the nursing handbooks and personal notes into embeddings. These embeddings will capture the semantic meaning of each section, allowing for efficient similarity-based searches.\n",
    "   - Both the nursing handbooks and the personal study notes will be embedded into the vector database.\n",
    "\n",
    "4. **Save to Vector DB (ChromaDB)**:\n",
    "   - Store the generated embeddings in **ChromaDB** for fast retrieval during RAG modeling.\n",
    "   - The vector database will allow the system to quickly access the most relevant information when a query is made.\n",
    "\n",
    "**Note**: Converting and embedding long documents like nursing handbooks may take some time (e.g., **15-30 minutes** per document).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Handbook of Clinical Nursing_ Medical-Surgical Nursing -- Joyce Fitzpatrick -- 2018 -- Springer Publishing Company -- 9780826130785 -- 26f2533f396508e653d45e0e76aadc53 -- Anna’s Archive.pdf']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List the raw files to convert\n",
    "os.listdir(knowledge_base_raw_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File `Handbook of Clinical Nursing_ Medical-Surgical Nursing -- Joyce Fitzpatrick -- 2018 -- Springer P`... is already converted.\n"
     ]
    }
   ],
   "source": [
    "document_converter = DocumentConverter()\n",
    "\n",
    "knowledge_base_raw_files = os.listdir(knowledge_base_raw_path)\n",
    "knowledge_base_converted_files = os.listdir(knowledge_base_converted_path)\n",
    "\n",
    "for file in knowledge_base_raw_files:\n",
    "\tfile_path = os.path.join(knowledge_base_raw_path, file)\n",
    "\tfile_name = os.path.splitext(file)[0]\n",
    "\n",
    "\t# Check if not file \n",
    "\tif not os.path.isfile(file_path):\n",
    "\t\tcontinue\n",
    "\n",
    "\t# Check if file is already converted\n",
    "\tif f\"{file_name}.md\" in knowledge_base_converted_files:\n",
    "\t\tprint(f\"File `{file[:97]}`... is already converted.\")\n",
    "\t\tcontinue\n",
    "\n",
    "\t# Convert the file into md format that is LLM friendly\n",
    "\tprint(f\"Converting file: `{file[:97]}`...\")\n",
    "\tconversion_result = document_converter.convert(file_path)\n",
    "\tmarkdown_text = conversion_result.document.export_to_markdown()\n",
    "\n",
    "\t# Write the converted file to the converted folder\n",
    "\twith open(os.path.join(knowledge_base_converted_path, f\"{file_name}.md\"), \"w\") as f:\n",
    "\t\tf.write(markdown_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 2: RAG Modeling\n",
    "\n",
    "Once the vector database is populated, the system will retrieve relevant information from both nursing handbooks and personal study notes. The retrieval will be augmented using an LLM (Large Language Model) for more accurate and contextually rich responses.\n",
    "\n",
    "#### Steps:\n",
    "\n",
    "1. **Retrieve Relevant Information**:\n",
    "   - When a query is input by the user (e.g., \"What are the symptoms of diabetes?\"), the system will retrieve the most relevant content from the vector database.\n",
    "   - ChromaDB will find the sections of the nursing handbooks or personal study notes that are most similar to the query.\n",
    "\n",
    "2. **Augment Response Using Deepseek LLM**:\n",
    "   - The retrieved sections will be passed through the **Deepseek LLM**, which will generate a response based on the content of the handbooks and notes.\n",
    "   - The LLM will combine the relevant information and format it into a coherent, accurate response tailored to the question.\n",
    "\n",
    "### Stage 3: Agentic RAG System\n",
    "\n",
    "The **Agentic Layer** adds an intelligent routing mechanism to the RAG system. Instead of simply retrieving data from a static source, the system will decide where to get the most relevant information based on the context of the query and whether the query pertains to the nursing handbooks or her personal study notes.\n",
    "\n",
    "#### Steps:\n",
    "\n",
    "1. **Incorporate Personal Study Notes (Transes)**:\n",
    "   - Personal study notes (transes) are documents or annotations written by the user, capturing key insights, case studies, or specific experiences.\n",
    "   - These notes will be embedded in the same way as the nursing handbooks and stored in the same vector database.\n",
    "\n",
    "2. **Agent Routes the Query**:\n",
    "   - When a user (nursing student) asks a question, the **agent** will decide whether to retrieve data from the nursing handbooks or her personal study notes.\n",
    "   - The agent will consider:\n",
    "     - The **context** of the question (general knowledge vs. personalized experiences).\n",
    "     - Whether her **personal study notes** are more relevant (e.g., if she’s already written notes on a particular case or condition).\n",
    "     - If the query is general, the agent will prioritize retrieving information from the **nursing handbooks**.\n",
    "\n",
    "3. **Retrieve from Both Sources**:\n",
    "   - The system retrieves information from both the **nursing handbooks** and **personal study notes** based on the agent’s decision.\n",
    "   - If the question pertains to something she has written down in her personal notes, the agent will prioritize retrieving those, combining them with general knowledge from the handbooks.\n",
    "\n",
    "4. **Augment Response Using Deepseek LLM**:\n",
    "   - The retrieved content from both sources is fed to the **Deepseek LLM**, which will merge the insights and generate a complete response.\n",
    "   - The LLM will ensure the answer is not only accurate but also personalized based on the notes, making it more useful and contextually rich.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-4-jiya-process-cmXo1Sk7-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
